#include "YoloProcessor.h"
#include <QDebug>
#include <QElapsedTimer>
#include <QtConcurrent>
#include <QBuffer>
#include <QImageReader>
#include <QDir>

// **æ„é€ å‡½æ•°**
YoloProcessor::YoloProcessor(QObject *parent) : QObject(parent) {
    net = cv::dnn::readNetFromONNX("D:/yolov8n_416.onnx");
    net.setPreferableBackend(cv::dnn::DNN_BACKEND_OPENCV);
    net.setPreferableTarget(cv::dnn::DNN_TARGET_CPU);
    frameBuffer = QImage(400, 400, QImage::Format_RGB888);
    frameBuffer.fill(Qt::black);
}

// **é€åƒç´ æ›´æ–° frameBuffer**
void YoloProcessor::addPixel(int x, int y, uchar r, uchar g, uchar b) {
    if (x >= 0 && x < frameBuffer.width() && y >= 0 && y < frameBuffer.height()) {
        frameBuffer.setPixel(x, y, qRgb(r, g, b));
    }
}

// **å¼‚æ­¥å¯åŠ¨ YOLO çº¿ç¨‹**
void YoloProcessor::frameReady() {
    // qDebug() << "[YOLO] frameReady() called!";

    if (processing.exchange(true)) {
        qDebug() << "[YOLO] Already processing, skipping...";
        return;
    }

    QtConcurrent::run([this]() {
        this->runInference();
    });
}

// **è¿è¡Œ YOLO æ¨ç†**
void YoloProcessor::runInference() {
//    qDebug() << "[YOLO] runInference() STARTED!";
//    qDebug() << "[YOLO] Running inference on thread:" << QThread::currentThread();

    // **è·å– frameBuffer**
    QImage localFrame;
    {
        QMutexLocker lock(&bufferMutex);
        localFrame = frameBuffer.copy();
    }

    if (localFrame.isNull()) {
//        qDebug() << "[YOLO] ERROR: FrameBuffer is null!";
        processing = false;
        return;
    }

    // **è½¬æ¢ QImage -> OpenCV Mat**
    cv::Mat mat(localFrame.height(), localFrame.width(), CV_8UC3,
                const_cast<uchar*>(localFrame.bits()), localFrame.bytesPerLine());

    // âœ… **è½¬æ¢ BGR -> RGB**
    cv::cvtColor(mat, mat, cv::COLOR_RGB2BGR);

    // **ğŸš€ é¢„å¤„ç†ä¿®æ­£**
    cv::Mat blob;
    cv::Size inputSize(416, 416);
    cv::dnn::blobFromImage(mat, blob, 1 / 255.0, inputSize, cv::Scalar(), true, false);

    // qDebug() << "[YOLO] OpenCV blob size:" << blob.size;

    // **æ¨ç†**
    net.setInput(blob);
    std::vector<cv::Mat> outputs;
    net.forward(outputs);

    // **ğŸš€ ç¡®ä¿è¾“å‡ºæ ¼å¼**
    cv::Mat output = outputs[0].reshape(1, 5).t();  // (3549, 5)
    // qDebug() << "[YOLO] OpenCV ONNX è¾“å‡ºå¼ é‡å½¢çŠ¶ï¼š" << output.size;

    // qDebug() << "[YOLO] Inference completed. Parsing results...";

    // **è§£ææ£€æµ‹ç»“æœ**
    std::vector<cv::Rect> boxes;
    std::vector<float> scores;

    for (int i = 0; i < output.rows; i++) {
        float* data = output.ptr<float>(i);  // ç›´æ¥å–å‡ºæ¯ä¸€è¡Œæ•°æ®
        float cx = data[0];
        float cy = data[1];
        float w = data[2];
        float h = data[3];
        float score = data[4];

        // âœ… **ç½®ä¿¡åº¦é—¨é™ä¿®æ­£**
        if (score < 0.85) continue;

        // âœ… **ä¿®æ­£è¾¹ç•Œæ¡†ï¼Œé˜²æ­¢åæ ‡è¶…å‡ºå›¾åƒå°ºå¯¸**
        int x1 = std::max(0, std::min(mat.cols, static_cast<int>(cx - w / 2)));
        int y1 = std::max(0, std::min(mat.rows, static_cast<int>(cy - h / 2)));
        int x2 = std::max(0, std::min(mat.cols, static_cast<int>(cx + w / 2)));
        int y2 = std::max(0, std::min(mat.rows, static_cast<int>(cy + h / 2)));

        boxes.push_back(cv::Rect(x1, y1, x2 - x1, y2 - y1));
        scores.push_back(score);
    }

    // **ğŸš€ éæå¤§å€¼æŠ‘åˆ¶ (NMS)**
    std::vector<int> indices;
    cv::dnn::NMSBoxes(boxes, scores, 0.3, 0.5, indices);

    // **è¾“å‡ºæœ€ç»ˆæ£€æµ‹æ¡†**
    std::vector<QRect> detectedBoxes;
//    qDebug() << "[YOLO] Raw Boxes Before NMS:";
//    for (size_t i = 0; i < boxes.size(); i++) {
//        qDebug() << "Box:" << boxes[i].x << boxes[i].y << boxes[i].width << boxes[i].height
//                 << "Score:" << scores[i];
//    }

    for (int i : indices) {
        // å–å‡º NMS å¤„ç†åçš„ box
        int original_x = boxes[i].x;
        int original_y = boxes[i].y;
        int original_width = boxes[i].width;
        int original_height = boxes[i].height;

        // ğŸš€ **æ”¾å¤§ 2 å€**
        int new_x = original_x * 2;
        int new_y = original_y * 2;
        int new_width = original_width * 2;
        int new_height = original_height * 2;

        detectedBoxes.push_back(QRect(new_x, new_y, new_width, new_height));
    }


    qDebug() << "[YOLO] Detected" << detectedBoxes.size() << "objects";

    // **å‘å°„ä¿¡å·**
    emit detectionFinished(detectedBoxes);

    // **é‡ç½® processing çŠ¶æ€**
    processing = false;
    // qDebug() << "[YOLO] Processing flag reset. Ready for next frame.";
}


// **æ£€æŸ¥ YOLO æ˜¯å¦æ­£åœ¨å¤„ç†**
bool YoloProcessor::isProcessing() const {
    bool status = processing.load();
    // qDebug() << "[YOLO] isProcessing() called. Current status:" << status;
    return status;
}

